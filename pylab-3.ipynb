{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86cecc2-d746-46e1-82df-54a4d7d8af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "fact=1\n",
    "for i in range(1,n+1):\n",
    "    fact=fact*i\n",
    "print(fact)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a5785a-0f34-438c-b88f-2923e67370ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mohamedriyas\n"
     ]
    }
   ],
   "source": [
    "s='mohamed'+'riyas'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad709a6e-bf10-49a3-bd8a-807df07740f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131650038828080\n"
     ]
    }
   ],
   "source": [
    "print(id(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c97dc0-f293-49b4-8f8c-73edfea7f0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mohamedriyaz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.replace('s','z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdca988-9971-41f8-a71e-59165db01e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î©\n"
     ]
    }
   ],
   "source": [
    "print('\\u03A9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39efc99c-446c-438c-8649-273467b123ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜€\n"
     ]
    }
   ],
   "source": [
    "print('\\U0001F600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e6d60f-b5c6-4422-a345-eae1ebc0bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î©\n",
      "ðŸ˜€\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "omega=unicodedata.lookup('GREEK CAPITAL LETTER OMEGA')\n",
    "smiley=unicodedata.lookup('GRINNING FACE')\n",
    "print(omega)\n",
    "print(smiley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c756e9-ad3f-40cb-8876-09438f8cd136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x1f600\n",
      "0x3a9\n",
      "0x62\n",
      "0xbb0\n"
     ]
    }
   ],
   "source": [
    "print(hex(ord('ðŸ˜€')))\n",
    "print(hex(ord('Î©')))\n",
    "print(hex(ord('b')))\n",
    "print(hex(ord('à®°')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875197a0-4f7f-4aef-8214-9096fc54200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/software/software/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/software/software/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/software/software/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/software/software/lib/python3.12/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/software/software/lib/python3.12/site-packages (from nltk) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "262ea945-c77d-4512-b801-354506eeaf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matlab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ef7915-b407-4f2e-9059-d5f76b6f2879",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/matlab/nltk_data'\n    - '/home/software/software/nltk_data'\n    - '/home/software/software/share/nltk_data'\n    - '/home/software/software/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m      6\u001b[0m     words\u001b[38;5;241m=\u001b[39mnltk\u001b[38;5;241m.\u001b[39mword_tokenize(sentence)\n\u001b[0;32m----> 7\u001b[0m     tagged_words\u001b[38;5;241m=\u001b[39mnltk\u001b[38;5;241m.\u001b[39mpos_tag(words)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tagged_words)\n",
      "File \u001b[0;32m/home/software/software/lib/python3.12/site-packages/nltk/tag/__init__.py:165\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[0;32m/home/software/software/lib/python3.12/site-packages/nltk/tag/__init__.py:107\u001b[0m, in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    105\u001b[0m     tagger\u001b[38;5;241m.\u001b[39mload(ap_russian_model_loc)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[0;32m/home/software/software/lib/python3.12/site-packages/nltk/tag/perceptron.py:167\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m    166\u001b[0m     AP_MODEL_LOC \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m--> 167\u001b[0m         find(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaggers/averaged_perceptron_tagger/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m PICKLE)\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[0;32m/home/software/software/lib/python3.12/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/home/matlab/nltk_data'\n    - '/home/software/software/nltk_data'\n    - '/home/software/software/share/nltk_data'\n    - '/home/software/software/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "texts=' im riyaz'\n",
    "sentences='hello world'\n",
    "for text in texts:\n",
    "    sentences= nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words=nltk.word_tokenize(sentence)\n",
    "        tagged_words=nltk.pos_tag(words)\n",
    "        print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ddc59-7cc8-47ca-9aab-24bc0486d164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
